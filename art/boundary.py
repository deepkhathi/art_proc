# pipeline: RGB image -> thresholding -> boundary image(s)
import time
import warnings
from typing import List, Literal, Optional, Tuple

import cv2
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.figure import Figure
from scipy import ndimage, stats
from skimage.color import gray2rgba
from skimage.exposure import (adjust_gamma, adjust_log, adjust_sigmoid,
                              equalize_adapthist, equalize_hist,
                              rescale_intensity)
from skimage.feature import peak_local_max
from skimage.filters.thresholding import threshold_multiotsu
from skimage.morphology import area_closing
from skimage.segmentation import find_boundaries, watershed
from skimage.transform import resize

from .utils import display_image, init_logger


class BoundaryImage():
    r"""Generate boundary image by providing workhorse pipeline.

    Steps are:
    1. Convert RGB to grayscale
    2. Perform Otsu-based thresholding
    3. Calculate watershed image and create connected boundary image

    Parameters
    ----------
    rgb_image : numpy.ndarray, shape=(N, M, 3)
        If image has shape=(N, M), assume that this is already in grayscale
    photo_correction : bool, default=False
        Apply photo exposure correction
        (only usable if the image is a photograph; see Notes 1)
    photo_corr_method : {"gamma", "sigmoid", "log", "clahe", "histeq", "contrast_stretch"},
    default="sigmoid"
        Method to apply contrast correction (see Notes 2)
    verbose : bool, default=False
        Generate plots for each step
    **kwargs
        Additional arguments for the relevant `photo_corr_method` skimage function

    Attributes
    ----------
    rgb_image : numpy.ndarray, shape=(N, M, 3)
        RGB image
    gray_image : numpy.ndarray, shape=(N, M)
        Grayscale image generated from input image
    threshold_image : numpy.ndarray, shape=(N, M)
        Retained threshold image generated by `BoundaryImage.threshold(...)`
    photo_correction : bool
        Whether to apply photo correction
    photo_corr_method : str
    photo_corrected_gray_image : numpy.ndarray, shape=(N, M)
        Contrast corrected grayscale image
    logger : logging.Logger
    verbose : bool, default=False

    Notes
    -----
    1. Photos and other images with non-uniform exposure distribution may affect
    image binarization and downstream watershed transform due to spurious bright regions
    2. Photo correction methods are implemented using `skimage.exposure` (see below)
            * "gamma" - `skimage.exposure.adjust_gamma`
            * "sigmoid" - `skimage.exposure.adjust_sigmoid`
            * "log" - `skimage.exposure.adjust_log`
            * "clahe" - `skimage.exposure.equalize_adapthist`
            * "histeq" - `skimage.exposure.equalize_hist`
            * "constrast_stretch" - `skimage.exposure.rescale_intensity`
    """

    def __init__(
        self,
        rgb_image: np.ndarray,
        photo_correction: bool = False,
        photo_corr_method: Literal["gamma", "sigmoid", "log",
                                   "clahe", "histeq", "contrast_stretch"] = "sigmoid",
        verbose: bool = False,
        **kwargs
    ):
        self.rgb_image = rgb_image
        self._orig_gray = False
        if len(self.rgb_image.shape) == 3:
            # check that there are only three channels
            if self.rgb_image.shape[-1] != 3:
                raise ValueError(
                    f"Number of channels ({self.rgb_image.shape[-1]}) != 3")
            self.gray_image: np.ndarray = cv2.cvtColor(
                self.rgb_image, cv2.COLOR_RGB2GRAY)
        elif len(self.rgb_image.shape) == 2:
            self.gray_image = self.rgb_image.copy()
            self._orig_gray = True
        else:
            raise ValueError(
                f"Dimensions of rgb_image must be (N, M, 3) "
                f"or (N, M); not {self.rgb_image.shape}")
        self.logger = init_logger("BoundaryImage")
        self.verbose = verbose
        self.photo_correction = photo_correction
        self.photo_corr_method = photo_corr_method
        self.photo_corr_gray_image: np.ndarray = self.gray_image.copy()
        if self.photo_correction:
            self.verbose = False
            self.photo_correct(
                photo_corr_method=photo_corr_method,
                **kwargs)
            self.verbose = verbose  # revert

    def _return_image(self, image: np.ndarray, return_flag: bool):
        return image if return_flag else None

    def _run_show(self) -> None:
        if self.verbose:
            plt.show()
        plt.close()

    def photo_correct(
        self,
        photo_corr_method: Literal["gamma", "sigmoid", "log",
                                   "clahe", "histeq", "contrast_stretch"] = "sigmoid",
        return_image: bool = False,
        **kwargs
    ) -> Tuple[Optional[np.ndarray], Optional[Figure]]:
        r"""Perform photo correction with `skimage.exposure`

        Parameters
        ----------
        photo_corr_method : {"gamma", "sigmoid", "log", "clahe", "histeq", "contrast_stretch"},
        default="sigmoid"
            Method to apply contrast correction (see Notes)
        return_image : bool, default=False
            Return exposure corrected grayscale image.
            Regardless, set `self.photo_corr_gray_image` as exposure-corrected image
        **kwargs
            Additional parameters for relevant `skimage.exposure` function

        Returns
        -------
        photo_corr_gray_image : numpy.ndarray, optional
            Exposure corrected image
        fig : matplotlib.figure.Figure, optional

        Raises
        ------
        NotImplementedError
            Unsupported `photo_corr_method`

        Notes
        -----
        1. Photo correction methods are implemented using `skimage.exposure` (see below)
            * "gamma" - `skimage.exposure.adjust_gamma`
            * "sigmoid" - `skimage.exposure.adjust_sigmoid`
            * "log" - `skimage.exposure.adjust_log`
            * "clahe" - `skimage.exposure.equalize_adapthist`
            * "histeq" - `skimage.exposure.equalize_hist`
            * "constrast_stretch" - `skimage.exposure.rescale_intensity`
        """
        avail_methods = {
            "gamma": adjust_gamma,
            "log": adjust_log,
            "sigmoid": adjust_sigmoid,
            "clahe": equalize_adapthist,
            "histeq": equalize_hist,
            "contrast_stretch": rescale_intensity
        }
        photo_corr_method = photo_corr_method.lower()
        if photo_corr_method not in [*avail_methods]:
            raise NotImplementedError(
                f"photo_corr_method = {photo_corr_method} is not supported "
                f"(available: {[*avail_methods]})")
        pc_gi = avail_methods[photo_corr_method](self.gray_image, **kwargs)
        self.photo_corr_gray_image: np.ndarray = pc_gi
        fig: Figure = None
        if self.verbose:
            fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(8, 5))
            display_image(self.gray_image, cmap="gray", ax=ax0)
            display_image(pc_gi, cmap="gray", ax=ax1)
        self.logger.info(
            f"Generated exposure-corrected image using {photo_corr_method} based correction")
        return (self._return_image(pc_gi, return_flag=return_image), fig)

    def threshold(
        self,
        n_classes: int,
        return_image: bool = False
    ) -> Tuple[Optional[np.ndarray], Optional[Figure]]:
        r"""Perform Otsu thresholding

        Parameters
        ----------
        n_classes : int
            Minimum number of classes = 2 (for binary)
        return_image : bool, default=True
            Return thresholded image

        Returns
        -------
        threshold_image : numpy.ndarray, optional
            Return if `return_image = True`
        fig : matplotlib.figure.Figure, optional
            Only generated and returned if `self.verbose = True`

        Raises
        ------
        ValueError
            n_classes must be >= 2
        """
        if n_classes < 2:
            raise ValueError(f"n_classes ({n_classes}) must be >= 2")
        thresholds = threshold_multiotsu(
            self.photo_corr_gray_image, classes=n_classes)
        self.threshold_image: np.ndarray = np.digitize(
            self.photo_corr_gray_image, bins=thresholds)
        fig: Figure = None
        if self.verbose:
            fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(10, 5))
            display_image(self.rgb_image, cmap=self._orig_gray, ax=ax0)
            display_image(self.photo_corr_gray_image, cmap=True, ax=ax1)
            display_image(self.threshold_image, cmap=True, ax=ax2)
        self.logger.info(
            f"Completed Otsu thresholding with n_classes = {n_classes}")
        return (self._return_image(self.threshold_image, return_image), fig)

    def generate_boundary_image(
        self,
        use_bkg: bool = False,
        boundary_mode: Literal["thick", "inner",
                               "outer", "subpixel"] = "inner",
        apply_post_filter: bool = False
    ) -> Tuple[np.ndarray, Optional[Figure]]:
        r"""Perform watershed segmentation and calculate boundary image via
        connected component boundary search

        Parameters
        ----------
        use_bkg: bool, default=False
            Include inverted background for finding outer edges. May be helpful
            in low fidelity images
        boundary_mode : {"thick", "inner", "outer", "subpixel"}, default="inner"
            Boundary mode for `skimage.segmentation.find_boundaries`
        apply_post_filter : bool, default=False
            Apply binary closing with an 8-neighborhood (connectivity=2)

        Returns
        -------
        boundary_image : numpy.ndarray, shape=(N, M)
            Binarized boundary image
        """
        uregs = np.unique(self.threshold_image.ravel())
        if not use_bkg:
            uregs = uregs[:-1]  # assume it is always last
            self.logger.info(
                "Dropping putative background region for boundary calculations")
        b_list: List[np.ndarray] = [None] * len(uregs)
        self.logger.info(
            f"Starting boundary process for all {len(uregs)} regions")
        top_start = time.time()
        for k in uregs:
            step_start = time.time()
            self.logger.info(
                f"Starting boundary calculation for region {k + 1} out of {len(uregs)}")
            thresh_region = np.zeros_like(self.threshold_image, dtype="uint8")
            thresh_region[self.threshold_image == k] = 1
            # watershed (Euclidean distance transform, peaks, watershed labels)
            distance_map = ndimage.distance_transform_edt(thresh_region)
            with warnings.catch_warnings():
                pl_start = time.time()
                warnings.simplefilter("ignore", FutureWarning)
                local_max_map = peak_local_max(
                    distance_map, min_distance=1,
                    indices=None, labels=thresh_region)
                self.logger.info(
                    f"Completed Local peak mapping on distance image in "
                    f"{time.time() - pl_start:.1f} seconds")
            markers = ndimage.label(local_max_map)[0]
            labels = watershed(-distance_map, markers=markers,
                               mask=thresh_region)
            # drop mode label (remove erroneous excess lines from transform)
            label_copy = labels.copy()
            mode = stats.mode(labels.ravel(), keepdims=None)[0]
            label_copy[labels != mode] = 1
            label_copy[labels == mode] = 0
            # get boundary
            b_list[k] = find_boundaries(label_copy, mode=boundary_mode)
            self.logger.info(
                f"Completed boundary calculation for region {k + 1} in "
                f"{time.time() - step_start:.0f} seconds")
        boundary_image = np.apply_along_axis(
            np.any, axis=2, arr=np.array(b_list).transpose([1, 2, 0]))
        self.logger.info(
            f"Completed all boundary generation in "
            f"{(time.time() - top_start) / 60:.2f} minutes")
        if apply_post_filter:
            boundary_image: np.ndarray = ~area_closing(
                ~boundary_image, connectivity=2)
        fig: Figure = None
        if self.verbose:
            fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(8, 6))
            display_image(self.rgb_image, cmap=self._orig_gray, ax=ax0)
            display_image(~boundary_image, cmap="gray", ax=ax1)
        return (boundary_image, fig)

    def run_pipeline(
        self,
        n_classes: int = 2,
        use_bkg: bool = False,
        boundary_mode: Literal["thick", "inner",
                               "outer", "subpixel"] = "inner",
        apply_post_filter: bool = False,
        resize_shape: Optional[Tuple[int, int]] = None,
        invert_colors: bool = True,
        transparent_background: bool = True
    ) -> np.ndarray:
        r"""Run complete extraction pipeline with
        threshold -> boundary extraction -> resizing

        Parameters
        ----------
        n_classes : int, default=2
            Minimum number of classes = 2 (for binary)
        use_bkg: bool, default=False
            Include inverted background for finding outer edges. May be helpful
            in low fidelity images
        boundary_mode : {"thick", "inner", "outer", "subpixel"}, default="inner"
            Boundary mode for `skimage.segmentation.find_boundaries`
        apply_post_filter : bool, default=False
            Apply binary closing with an 8-neighborhood (connectivity=2)
        resize_shape : (int, int), optional
            Resize to target shape. If parent image is rotated relative to target shape,
            flip the target shape (e.g., width <> height)
        invert_colors : bool, default=True
            Invert binary image for contrast
        transparent_background : bool, default=True
            Convert to transparent background by converting to RGB(A)

        Returns
        -------
        processed_boundary_image : numpy.ndarray
            If transparent_background, shape=(N, M, 4); otherwise, (N, M)
        """
        self.threshold(n_classes=n_classes)
        self._run_show()
        boundary_image, _ = self.generate_boundary_image(
            use_bkg=use_bkg,
            boundary_mode=boundary_mode,
            apply_post_filter=apply_post_filter)
        self._run_show()
        resized_bim = boundary_image.copy()
        if resize_shape is not None:
            width, height = resize_shape
            sc_fac = width / height
            b_shape = boundary_image.shape
            bsc_fac = b_shape[0] / b_shape[1]
            self.logger.info(
                f"Resize to {resize_shape} (scaling factor = {sc_fac:.2f}); "
                f"current image is {boundary_image.shape} (scaling factor = {bsc_fac:.2f})")
            conv_shape = resize_shape
            if np.sign(sc_fac - 1) != np.sign(bsc_fac - 1):
                conv_shape = tuple(np.flip(resize_shape))
                nsc_fac = conv_shape[0] / conv_shape[1]
                self.logger.info(
                    "NOTE: flipping target shape (swap width and height) due to scaling mismatch; "
                    f"new target shape: {conv_shape} (scaling factor = {nsc_fac:.2f})")
            resized_bim: np.ndarray = resize(
                boundary_image, conv_shape, anti_aliasing=False)
            self.logger.info(
                f"Resized image from {b_shape} to {resized_bim.shape}")
        processed_boundary_image = resized_bim.copy()
        if transparent_background and invert_colors:
            processed_boundary_image = gray2rgba(~resized_bim * 1.)
            processed_boundary_image[:, :, -1] = resized_bim * 1.0
            self.logger.info(
                f"Invert color and convert to transparent background")
        elif transparent_background:
            processed_boundary_image = gray2rgba(resized_bim * 1.)
            processed_boundary_image[:, :, -1] = ~resized_bim * 1.0
            self.logger.info(f"Convert to transparent background")
        elif invert_colors:
            processed_boundary_image = ~resized_bim
        return processed_boundary_image
